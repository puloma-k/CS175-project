{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/john/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as df\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Help With Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processWord(word):\n",
    "    return re.sub(r'\\W+', '', word)\n",
    "\n",
    "def tokenize(x, y, onehot_dict):\n",
    "    tokenized_x = [[onehot_dict[processWord(word)] for word in str(sentence).lower().split() if processWord(word) in onehot_dict] for sentence in x['Review'].values]\n",
    "\n",
    "    encoded_y = [1 if generation_status == 1 else 0 for generation_status in y['Generated'].values]\n",
    "    return np.array(tokenized_x), np.array(encoded_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import OneHot Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"onehot_dicts/osf_onehot.pkl\",\"rb\") as file:\n",
    "    osf_onehot_dict = pickle.load(file)\n",
    "with open(\"onehot_dicts/imbalanced_onehot.pkl\",\"rb\") as file:\n",
    "    imbalanced_onehot_dict = pickle.load(file)\n",
    "with open(\"onehot_dicts/oversampled_onehot.pkl\",\"rb\") as file:\n",
    "    oversampled_onehot_dict = pickle.load(file)\n",
    "with open(\"onehot_dicts/undersampled_onehot.pkl\",\"rb\") as file:\n",
    "    undersampled_onehot_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Small Amount of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSFTest = df.read_csv('partitions/smallOSFTest.csv')\n",
    "OSFXtest = OSFTest.drop(columns=\"Generated\")\n",
    "OSFytest = OSFTest.drop(columns=\"Review\")\n",
    "\n",
    "combinedTest = df.read_csv('partitions/smallCombinedTest.csv')\n",
    "combinedXtest = combinedTest.drop(columns=\"Generated\")\n",
    "combinedYtest = combinedTest.drop(columns=\"Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for OSF model to test on Small Combined Imbalanced Test Dataset\n",
    "osf_combinedXtest_input, osf_combinedYtest_input = tokenize(combinedXtest, combinedYtest, osf_onehot_dict)\n",
    "# Input for Imbalanced model to test on Small Combined Imbalanced Test Dataset\n",
    "imbalanced_combinedXtest_input, imbalanced_combinedYtest_input = tokenize(combinedXtest, combinedYtest, imbalanced_onehot_dict)\n",
    "# Input for Oversampled model to test on Small Combined Imbalanced Test Dataset\n",
    "oversampled_combinedXtest_input, oversampled_combinedYtest_input = tokenize(combinedXtest, combinedYtest, oversampled_onehot_dict)\n",
    "# Input for Undersampled model to test on Small Combined Imbalanced Test Dataset\n",
    "undersampled_combinedXtest_input, undersampled_combinedYtest_input = tokenize(combinedXtest, combinedYtest, undersampled_onehot_dict)\n",
    "\n",
    "# Input for OSF model to test on Small OSF Test dataset\n",
    "osf_OSFXtest, osf_OSFYtest = tokenize(OSFXtest, OSFytest, osf_onehot_dict)\n",
    "# Input for Imbalanced model to test on Small OSF Test dataset\n",
    "imbalanced_OSFXtest, imbalanced_OSFYtest = tokenize(OSFXtest, OSFytest, imbalanced_onehot_dict)\n",
    "# Input for Oversampled model to test on Small OSF Test dataset\n",
    "oversampled_OSFXtest, oversampled_OSFYtest = tokenize(OSFXtest, OSFytest, oversampled_onehot_dict)\n",
    "# Input for imbalanced model to test on Small OSF Test dataset\n",
    "undersampled_OSFXtest, undersampled_OSFYtest = tokenize(OSFXtest, OSFytest, undersampled_onehot_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad Input Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padVectors(sentences, length):\n",
    "    vectors = np.zeros((len(sentences), length), dtype=int)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            l = min(length, len(sentence))\n",
    "            vectors[i, -l:] = np.array(sentence)[:l]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf_combinedXtest_padded = padVectors(osf_combinedXtest_input, 250)\n",
    "imbalanced_combinedXtest_padded = padVectors(imbalanced_combinedXtest_input, 250)\n",
    "oversampled_combinedXtest_padded = padVectors(oversampled_combinedXtest_input, 250)\n",
    "undersampled_combinedXtest_padded = padVectors(undersampled_combinedXtest_input, 250)\n",
    "\n",
    "osf_OSFXtest_padded = padVectors(osf_OSFXtest, 250)\n",
    "imbalanced_OSFXtest_padded = padVectors(imbalanced_OSFXtest, 250)\n",
    "oversampled_OSFXtest_padded = padVectors(oversampled_OSFXtest, 250)\n",
    "undersampled_OSFXtest_padded = padVectors(undersampled_OSFXtest, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf_combined = torch.utils.data.TensorDataset(torch.from_numpy(osf_combinedXtest_padded), torch.from_numpy(osf_combinedYtest_input))\n",
    "imbalanced_combined = torch.utils.data.TensorDataset(torch.from_numpy(imbalanced_combinedXtest_padded), torch.from_numpy(imbalanced_combinedYtest_input))\n",
    "oversampled_combined = torch.utils.data.TensorDataset(torch.from_numpy(oversampled_combinedXtest_padded), torch.from_numpy(oversampled_combinedYtest_input))\n",
    "undersampled_combined = torch.utils.data.TensorDataset(torch.from_numpy(undersampled_combinedXtest_padded), torch.from_numpy(undersampled_combinedYtest_input))\n",
    "\n",
    "osf_OSF = torch.utils.data.TensorDataset(torch.from_numpy(osf_OSFXtest_padded), torch.from_numpy(osf_OSFYtest))\n",
    "imbalanced_OSF = torch.utils.data.TensorDataset(torch.from_numpy(imbalanced_OSFXtest_padded), torch.from_numpy(imbalanced_OSFYtest))\n",
    "oversampled_OSF = torch.utils.data.TensorDataset(torch.from_numpy(oversampled_OSFXtest_padded), torch.from_numpy(oversampled_OSFYtest))\n",
    "undersampled_OSF = torch.utils.data.TensorDataset(torch.from_numpy(undersampled_OSFXtest_padded), torch.from_numpy(undersampled_OSFYtest))\n",
    "\n",
    "# batch size for dataloaders\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "osf_combined_loader = torch.utils.data.DataLoader(osf_combined, batch_size=BATCH_SIZE, drop_last=True)\n",
    "imbalanced_combined_loader = torch.utils.data.DataLoader(imbalanced_combined, batch_size=BATCH_SIZE, drop_last=True)\n",
    "oversampled_combined_loader = torch.utils.data.DataLoader(oversampled_combined, batch_size=BATCH_SIZE, drop_last=True)\n",
    "undersampled_combined_loader = torch.utils.data.DataLoader(undersampled_combined, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "osf_OSF_loader = torch.utils.data.DataLoader(osf_OSF, batch_size=BATCH_SIZE, drop_last=True)\n",
    "imbalanced_OSF_loader = torch.utils.data.DataLoader(imbalanced_OSF, batch_size=BATCH_SIZE, drop_last=True)\n",
    "oversampled_OSF_loader = torch.utils.data.DataLoader(oversampled_OSF, batch_size=BATCH_SIZE, drop_last=True)\n",
    "undersampled_OSF_loader = torch.utils.data.DataLoader(undersampled_OSF, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewClassifier(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim, hidden_dim):\n",
    "        super(ReviewClassifier,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        batch_size = x.size(0)\n",
    "        # embedding layer\n",
    "        embeds = self.embedding(x) \n",
    "        # LSTM layer\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
    "        # Feed Forward Network\n",
    "        out = self.fc(lstm_out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sigmoid(out)\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # create zero tensors for the hidden state and cell state of LSTM\n",
    "        h0 = torch.zeros((1,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((1,batch_size,self.hidden_dim)).to(device)\n",
    "        return (h0,c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Calculating Accuracy, False Negatives and False Postives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(pred, label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()\n",
    "\n",
    "def return_misses(inputs, output, labels, vocab):\n",
    "    pred = torch.round(output.squeeze())\n",
    "    labels = labels.squeeze()\n",
    "    misses = []\n",
    "    miss_index = []\n",
    "    false_negative = 0\n",
    "    false_positive = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] != labels[i]:\n",
    "            if pred[i] == 0:\n",
    "                false_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "            misses.append(' '.join([vocab[inputs[i][j].item()] for j in range(len(inputs[i])) if inputs[i][j].item() != 0]))\n",
    "            miss_index.append(i)\n",
    "    return misses, miss_index, false_negative, false_positive\n",
    "\n",
    "def do_test_stats(model, vocabulary, test_loader):\n",
    "    test_h = model.init_hidden(BATCH_SIZE)\n",
    "    test_losses = []\n",
    "    test_acc = 0.0\n",
    "    tot_misses = []\n",
    "    model.eval()\n",
    "    vocab_r = {v: k for k, v in vocabulary.items()}\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    tot_outputs = 0\n",
    "    tot_labels = 0\n",
    "    count = 0\n",
    "    miss_indices = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            test_h = tuple([each.data for each in test_h])\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            output, test_h = model(inputs, test_h)\n",
    "            test_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "            test_losses.append(test_loss.item())\n",
    "            misses, miss_index, fneg, fpos = return_misses(inputs, output, labels, vocab_r)\n",
    "            tot_misses.extend(misses)\n",
    "            miss_indices.extend([count*64+i for i in miss_index])\n",
    "            false_positives += fpos\n",
    "            false_negatives += fneg\n",
    "            accuracy = acc(output,labels)\n",
    "            test_acc += accuracy\n",
    "\n",
    "            tot_outputs = output if type(tot_outputs) == type(0) else torch.cat((tot_outputs, output))\n",
    "            tot_labels = labels if type(tot_labels) == type(0) else torch.cat((tot_labels, labels))\n",
    "            count += 1\n",
    "\n",
    "    test_loss = np.mean(test_losses)\n",
    "    test_acc = test_acc/(64*count)\n",
    "    print(f'test_loss : {test_loss}')\n",
    "    print(f'test_accuracy : {test_acc*100}')\n",
    "    print(f'false_positive : {false_positives / (64*count)} ')\n",
    "    print(f'false_negatives : {false_negatives / (64*count)} ')\n",
    "    return tot_outputs, tot_labels, tot_misses, miss_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method To Run Model on Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(one_hot_dict, data_loader, model_state_dict_name, testX, testY):\n",
    "    vocabulary_size = len(one_hot_dict)+1\n",
    "    embedding_dim = 64\n",
    "    hidden_dim = 256\n",
    "\n",
    "    # Import Model\n",
    "    model = ReviewClassifier(vocabulary_size, embedding_dim, hidden_dim)\n",
    "    if is_cuda:\n",
    "        model.load_state_dict(torch.load(model_state_dict_name))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_state_dict_name, map_location=torch.device('cpu')))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # Do Test Stats\n",
    "    osf_OSF_tot_outputs, osf_OSF_tot_labels, osf_misses, osf_miss_indices = do_test_stats(model, one_hot_dict, data_loader)\n",
    "    print(\"\\nLabel of 1 means Real Review. Label of 0 means Fake or Computer Generated. Printing 4 of the miss predicted inputs\")\n",
    "\n",
    "    for i in osf_miss_indices[:4]:\n",
    "        print(\"\\nLabel:\", testY.iat[i,0])\n",
    "        print(\"Model Prediction:\", round(osf_OSF_tot_outputs[i].item()))\n",
    "        print(\"Input Sentence:\", testX.iat[i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Testing on smallOSFTest.csv Dataset (Note Small Datasize so Accuracy does not reflect on entire dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Trained on OSF Dataset on Small OSF Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss : 0.18482580284277597\n",
      "test_accuracy : 92.70833333333334\n",
      "false_positive : 0.026041666666666668 \n",
      "false_negatives : 0.046875 \n",
      "\n",
      "Label of 1 means Real Review. Label of 0 means Fake or Computer Generated. Printing 4 of the miss predicted inputs\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Easy to use and works great I read reviews on this product all over the web before buying it and agree very good product\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: Maddix is out there with a bunch of crazy people He is a detective a crimefighter a\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: Our church has several fundraisers and an outdoor garden area I will be purchasing a new one for the garden area  The house is designed to be a very attractive place to live and provide a nice environment to live in  The outdoor garden area is very well made and has several sun and humidity controls  I will be buying a second one for the backyard area as well  I will be posting pictures of the outdoor garden and the garden as well as photos of the garden from the outside of the house  The house will be fairly large and it will not be too big for a small room  I have used the house for over a year and it is still\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Great for the girls Im 36d and bought a small\n"
     ]
    }
   ],
   "source": [
    "test_model(osf_onehot_dict, osf_OSF_loader, \"state_dicts/best_acc_OSF_state_dict.pt\", OSFXtest, OSFytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Trained on Imbalanced Combined Dataset on Small OSF Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss : 0.33766421178976697\n",
      "test_accuracy : 86.97916666666666\n",
      "false_positive : 0.041666666666666664 \n",
      "false_negatives : 0.08854166666666667 \n",
      "\n",
      "Label of 1 means Real Review. Label of 0 means Fake or Computer Generated. Printing 4 of the miss predicted inputs\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Easy to use and works great I read reviews on this product all over the web before buying it and agree very good product\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Very great read keeps you on the edge of your seat its a must read book I would advise everyone to get and read so far so good\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: Maddix is out there with a bunch of crazy people He is a detective a crimefighter a\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: Great look nice by Im a size 10 5 I normally wear a medium in jeans and this is a perfect fit I am a 32D and the waist is very large\n"
     ]
    }
   ],
   "source": [
    "test_model(imbalanced_onehot_dict, imbalanced_OSF_loader, \"state_dicts/best_acc_imbalanced_state_dict.pt\", OSFXtest, OSFytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Trained on Oversampled Combined Dataset on Small OSF Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss : 0.4014149059851964\n",
      "test_accuracy : 92.96875\n",
      "false_positive : 0.06510416666666667 \n",
      "false_negatives : 0.005208333333333333 \n",
      "\n",
      "Label of 1 means Real Review. Label of 0 means Fake or Computer Generated. Printing 4 of the miss predicted inputs\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: this is a great spotlightits very bright an cast a concentrated beam for a long distancei feel this spotlight will be great for many uses an would recomend to anybody\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Somewhat hard to clean not as convenient as I had hoped\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: This car beats the pants off the other remote control toys because1 it lights up2 big soft rubber wheels dont cause damage when they bump furniture3 the twisting action is cool4 gets itself out of trouble5 it lights upThis toy is the best bang for the buck  gift for a 9year old and hit of the party and beyond\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: My 5 year old grandson loves these  He uses them to drive Dino construction toys\n"
     ]
    }
   ],
   "source": [
    "test_model(oversampled_onehot_dict, oversampled_OSF_loader, \"state_dicts/best_acc_oversampled_state_dict.pt\", OSFXtest, OSFytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Trained on Undersampled Combined Dataset on Small OSF Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss : 0.7437137961387634\n",
      "test_accuracy : 61.71875\n",
      "false_positive : 0.3697916666666667 \n",
      "false_negatives : 0.013020833333333334 \n",
      "\n",
      "Label of 1 means Real Review. Label of 0 means Fake or Computer Generated. Printing 4 of the miss predicted inputs\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Works really good Keep the usb 30 fast meaning it is real usb 30 cable\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Easy to use and works great I read reviews on this product all over the web before buying it and agree very good product\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: We were really worried this would not work but it works great you just screw your bulb in the adapter and plug it into your weird lamp and voila\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Very great read keeps you on the edge of your seat its a must read book I would advise everyone to get and read so far so good\n"
     ]
    }
   ],
   "source": [
    "test_model(undersampled_onehot_dict, undersampled_OSF_loader, \"state_dicts/best_acc_undersampled_state_dict.pt\", OSFXtest, OSFytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Testing on smallCombinedTest.csv Dataset (Note Small Datasize so Accuracy does not reflect on entire dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Trained on OSF Dataset on Small, Imbalanced, Combined Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss : 1.014183759689331\n",
      "test_accuracy : 86.45833333333334\n",
      "false_positive : 0.015625 \n",
      "false_negatives : 0.11979166666666667 \n",
      "\n",
      "Label of 1 means Real Review. Label of 0 means Fake or Computer Generated. Printing 4 of the miss predicted inputs\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: Terrific hearty Italian food in an awesome atmosphere\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: I used to love the Raspberry Habernero wings but now they taste differnet im very dissapointed i dont know why this is There are very few good people in the waitstaff and sometimes ive heard yelling from the kitchen Sounds like the chef or manager back there needs a visit from the dept of labor Get a pizza they are fantastic and ask for Will to be your server\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: I went in to try this place out I wasnt sure what to expect First the decor and atmosphere was really cool I felt very comfortable I sat at the Bar to eat only to be greeted by this Beautful redhead it was very hard to keep my eyes off of her She turned out to not only be my server but she was also the Bartender The service was great as was the conversation She seemed to really know alot about all of the different wines and creative drinks All I tried were fantastic Then came the food It was very good I tried some of the different BruschettasWOW Also some of the meats and cheeses againWOW All of the staff was very friendly alert and well knowledged about the food and drinks I highly recomend this place if not for the food You should at least go have a drink and check out that Bartender winkwink\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: I love this place Great atmosphere very service minded staff great location and killer breakfast We liked it so much that we came back for breakfast 2 days later to eat more of the lovely food The best eggs benedict I have tried and the avocado toast was awesome as well Highly recommended from me\n"
     ]
    }
   ],
   "source": [
    "test_model(osf_onehot_dict, osf_combined_loader, \"state_dicts/best_acc_OSF_state_dict.pt\", combinedXtest, combinedYtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Trained on Imbalanced Combined Dataset on Small, Imbalanced, Combined Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss : 0.35364994406700134\n",
      "test_accuracy : 86.97916666666666\n",
      "false_positive : 0.005208333333333333 \n",
      "false_negatives : 0.125 \n",
      "\n",
      "Label of 1 means Real Review. Label of 0 means Fake or Computer Generated. Printing 4 of the miss predicted inputs\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: Terrific hearty Italian food in an awesome atmosphere\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: I used to love the Raspberry Habernero wings but now they taste differnet im very dissapointed i dont know why this is There are very few good people in the waitstaff and sometimes ive heard yelling from the kitchen Sounds like the chef or manager back there needs a visit from the dept of labor Get a pizza they are fantastic and ask for Will to be your server\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: Went againstill love it as much as the first time and every time after\n",
      "\n",
      "Label: 0\n",
      "Model Prediction: 1\n",
      "Input Sentence: I went in to try this place out I wasnt sure what to expect First the decor and atmosphere was really cool I felt very comfortable I sat at the Bar to eat only to be greeted by this Beautful redhead it was very hard to keep my eyes off of her She turned out to not only be my server but she was also the Bartender The service was great as was the conversation She seemed to really know alot about all of the different wines and creative drinks All I tried were fantastic Then came the food It was very good I tried some of the different BruschettasWOW Also some of the meats and cheeses againWOW All of the staff was very friendly alert and well knowledged about the food and drinks I highly recomend this place if not for the food You should at least go have a drink and check out that Bartender winkwink\n"
     ]
    }
   ],
   "source": [
    "test_model(imbalanced_onehot_dict, imbalanced_combined_loader, \"state_dicts/best_acc_imbalanced_state_dict.pt\", combinedXtest, combinedYtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Trained on Oversampled Combined Dataset on Small, Imbalanced, Combined Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss : 0.29389676948388416\n",
      "test_accuracy : 90.36458333333334\n",
      "false_positive : 0.08854166666666667 \n",
      "false_negatives : 0.0078125 \n",
      "\n",
      "Label of 1 means Real Review. Label of 0 means Fake or Computer Generated. Printing 4 of the miss predicted inputs\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: The place is cute and cozy and right in the heart of one of my favorite neighborhoods in the city Its a great place to stop in late and have a dessert and tea The staff are extremely friendly and make you feel right at home My wife and I enjoy Cluny when we are in the area\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Love this place Food is yummy But Im definitely giving a chunk of my paycheck to this restaurant Lol Worth it\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: One of the best pizzas Ive ever eaten So so good Need to go back asap Lines are long so I would suggest making a reservation Its also BYOB bring a bottle of wine so that you can enjoy it with the delicious pizza \n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: This is the worst food that I have ever eaten Not the worst Chinese food The worst food The buttered roll and cold coffee that they gave me in the Mineola NY jail in 1985 was better than this Once on a dare I bought and ate a chicken salad sandwich from a oneeyed ninety year old Mayan woman on a hot second class bus between Cancun and Merida Mexico In JulyThat sandwich was better than this beef chow fun Pure poison\n"
     ]
    }
   ],
   "source": [
    "test_model(oversampled_onehot_dict, oversampled_combined_loader, \"state_dicts/best_acc_oversampled_state_dict.pt\",  combinedXtest, combinedYtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model Trained on Undersampled Combined Dataset on Small, Imbalanced, Combined Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss : 0.5755191991726557\n",
      "test_accuracy : 67.44791666666666\n",
      "false_positive : 0.28125 \n",
      "false_negatives : 0.044270833333333336 \n",
      "\n",
      "Label of 1 means Real Review. Label of 0 means Fake or Computer Generated. Printing 4 of the miss predicted inputs\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: The place is cute and cozy and right in the heart of one of my favorite neighborhoods in the city Its a great place to stop in late and have a dessert and tea The staff are extremely friendly and make you feel right at home My wife and I enjoy Cluny when we are in the area\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: We found our way here in search of ceviche and left very satisfied Definitely try the ceviche obv lobster taquitos and sangria braised short ribs To top it off the service was excellent Well definitely be back\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: Love this place Food is yummy But Im definitely giving a chunk of my paycheck to this restaurant Lol Worth it\n",
      "\n",
      "Label: 1\n",
      "Model Prediction: 0\n",
      "Input Sentence: The grits and poached eggs are sooooo good Good enough to crave for days Everything here is fantastic including the service and atmosphere My husband loves the burger with egg  gets it every time\n"
     ]
    }
   ],
   "source": [
    "test_model(undersampled_onehot_dict, undersampled_combined_loader, \"state_dicts/best_acc_undersampled_state_dict.pt\", combinedXtest, combinedYtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
